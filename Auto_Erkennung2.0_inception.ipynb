{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darlegung der Motivation und Problemstellung\n",
    "    Bilderkkenung ob ein Auto vorhanden ist oder nicht.\n",
    "    -> Ziel: 95% Accuracy auf Test-Datensatz\n",
    "        Erkennung von eigenen Bilder außerhalb der Daten.\n",
    "Beschreibung des Datensatzes\n",
    "mit dem externen Notebook \"Verschieben.jpynb\" können Die Daten auf die verschiedenen bereiche verteilt werden (Test/Val/Train)\n",
    "    1. Stanford Cars Dataset: [1]​\n",
    "        16000 Bilder von PKWs für feinere Klassifizierung und Markenerkennung ​\n",
    "    2. Fahrzeugerkennungsdatensatz: [2]​\n",
    "        Dashcam Aufnahmen, 8000 Bilder mit PKWs, 8000 Bilder ohne PKWs ​\n",
    "    3. Natural Images: [3]​\n",
    "        6000 Bilder von Menschen, Motorrädern, div. Objekten​\n",
    "    4. CalTec Home Objects: [4]​\n",
    "        300 Bilder von Objekten\n",
    "Dokumentation von Erkenntnissen, die aus dem Training des Modells abgeleitet werden konnten\n",
    "    1. Die Erstellung eines komplett neuen CNNs ist mit der begrentzten Rechenleistung nur schwer umsetztbar\n",
    "    2. Das Nachtraining eines vortrainierten CNNs ist deutlich effecktiver und universeller einsetzbar, da es auf neue Bilder außerhalb der Daten besser performt.\n",
    "Evaluation des trainierten Modells\n",
    "    1. Die erzielte genauigkeit von über 99% erfüllt die Anforderungen von 95% komplett\n",
    "Fazit und Ausblick\n",
    "    In der Extra Datei \"Modell_Testen.jpynb\" können eigene Bilder getestet werden\n",
    "Quellen\n",
    "    Datensätze​\n",
    "        [1] https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset?select=cars_train (letzter Zugriff: 30.05.2024)​\n",
    "        [2] https://www.kaggle.com/datasets/brsdincer/vehicle-detection-image-set (letzter Zugriff: 30.05.2024)​\n",
    "        [3] https://www.kaggle.com/datasets/prasunroy/natural-images (letzter Zugriff: 30.05.2024)​\n",
    "        [4] https://www.kaggle.com/datasets/ashfaqsyed/caltech-homeobjects (letzter Zugriff: 30.05.2024)​\n",
    "CODE​\n",
    "        https://cloud.google.com/tpu/docs/inception-v3-advanced?hl=de (letzter Zugriff: 05.06.2024)​\n",
    "        https://students:cBcjcTxofwXJ-y_ouXsx@gitlab.gwdg.de/christian.graef/engineering-deep-nets.git (Letzter Zugriff: 03.06.2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "path_train_car = './data/vehicles'\n",
    "path_train_nocar = './data/non-vehicles'\n",
    "path_train = './data/'\n",
    "path_val_car = './Validation/vehicles'\n",
    "path_val_nocar = './Validation/non-vehicles'\n",
    "path_val = './Validation/'\n",
    "path_test_car = './Test/vehicles'\n",
    "path_test_nocar = './Test/non-vehicles'\n",
    "path_test = './Test'\n",
    "\n",
    "# Verzeichnis mit unseren Trainingsdaten der Klasse 'car'\n",
    "train_cars_dir = os.path.join(path_train_car)\n",
    "test_cars_dir = os.path.join(path_test_car)\n",
    "validation_cars_dir = os.path.join(path_val_car)\n",
    "\n",
    "# Verzeichnis mit unseren Trainingsdaten der Klasse 'nocar'\n",
    "train_nocars_dir = os.path.join(path_train_nocar)\n",
    "test_nocars_dir = os.path.join(path_test_nocar)\n",
    "validation_nocars_dir = os.path.join(path_val_nocar)\n",
    "\n",
    "# Ausgabe der Anzahl\n",
    "print('Anzahl Bilder im Verzeichnis Cars:', len(os.listdir(train_cars_dir)))\n",
    "print('Anzahl Bilder im Verzeichnis no Cars:', len(os.listdir(train_nocars_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=90,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1/255)\n",
    "\n",
    "# Zähle die Anzahl der Bilder im Trainingsverzeichnis\n",
    "num_train_images = len(os.listdir(train_cars_dir)) + len(os.listdir(train_nocars_dir))\n",
    "\n",
    "batchsize = 256\n",
    "batchsize_val = 64\n",
    "epochen = 20 #Kein Overfitting\n",
    "\n",
    "# Berechne die Schritte pro Epoche\n",
    "#stepsperepoch = 1376\n",
    "#int((num_train_images / batchsize)/20)\n",
    "\n",
    "# Bilder aus dem Trainingsdatensatz fließen in Paketen (batches) von 256 in train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path_train,  # Quellverzeichnis für Trainingsdaten\n",
    "        target_size=(150, 150),  # Alle Bilder werden auf 150x150 Pixel skaliert\n",
    "        batch_size=batchsize,\n",
    "        # Konfiguriere Labels für eine binäre Klassifikation\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "# Bilder aus dem Trainingsdatensatz fließen in Paketen (batches) von 64 in train_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        path_val,  # Quellverzeichnis für Trainingsdaten\n",
    "        target_size=(150, 150),  # Alle Bilder werden auf 150x150 Pixel skaliert\n",
    "        batch_size=batchsize_val,\n",
    "        # Konfiguriere Labels für eine binäre Klassifikation\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "# Generator für Testdaten\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    path_test,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batchsize,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the weights file you downloaded into a variable\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      #steps_per_epoch=stepsperepoch,  \n",
    "      epochs=epochen,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf die Metriken aus dem history-Objekt\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Zugriff auf die Anzahl der Epochen\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_accuracy, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Validation Accuracy')\n",
    "plt.title('Training und Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training und Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell auf Testdaten evaluieren\n",
    "eval_result = model.evaluate(test_generator)\n",
    "\n",
    "# Ausgabe von Genauigkeit und Verlust\n",
    "print(\"Test Genauigkeit:\", eval_result[1])\n",
    "print(\"Test Verlust:\", eval_result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell speicher\n",
    "model.save('/Users/cristobalschmidt/DeepDrive2.0/h5_'+str(epochen)+'epochs_150x150.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

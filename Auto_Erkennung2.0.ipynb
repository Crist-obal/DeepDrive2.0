{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "# Verzeichnis mit unseren Trainingsdaten der Klasse 'car'\n",
    "train_cars_dir = os.path.join('./data/vehicles')\n",
    "test_cars_dir = os.path.join('./Test/vehicles')\n",
    "validation_cars_dir = os.path.join('./Validation/vehicles')\n",
    "\n",
    "# Verzeichnis mit unseren Trainingsdaten der Klasse 'nocar'\n",
    "train_nocars_dir = os.path.join('./data/non-vehicles')\n",
    "test_nocars_dir = os.path.join('./Test/non-vehicles')\n",
    "validation_nocars_dir = os.path.join('./Validation/non-vehicles')\n",
    "\n",
    "\n",
    "\n",
    "#train_cars_names = os.listdir(train_cars_dir)\n",
    "#train_nocars_names = os.listdir(train_nocars_dir)\n",
    "\n",
    "print('Anzahl Bilder im Verzeichnis Cars:', len(os.listdir(train_cars_dir)))\n",
    "print('Anzahl Bilder im Verzeichnis no Cars:', len(os.listdir(train_nocars_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Zähle die Anzahl der Bilder im Trainingsverzeichnis\n",
    "num_train_images = len(os.listdir(train_cars_dir)) + len(os.listdir(train_nocars_dir))\n",
    "\n",
    "batchsize = 64\n",
    "epochs = 100\n",
    "\n",
    "# Berechne die Schritte pro Epoche\n",
    "stepsperepoch = int((num_train_images / batchsize)/20)\n",
    "\n",
    "# Bilder aus dem Trainingsdatensatz fließen in Paketen (batches) von 128 in train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './data/',  # Quellverzeichnis für Trainingsdaten\n",
    "        target_size=(64, 64),  # Alle Bilder werden auf 300x300 Pixel skaliert\n",
    "        batch_size=batchsize,\n",
    "        # Konfiguriere Labels für eine binäre Klassifikation\n",
    "        class_mode='binary')\n",
    "\n",
    "# Bilder aus dem Trainingsdatensatz fließen in Paketen (batches) von 128 in train_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './Test/',  # Quellverzeichnis für Trainingsdaten\n",
    "        target_size=(64, 64),  # Alle Bilder werden auf 300x300 Pixel skaliert\n",
    "        batch_size=batchsize,\n",
    "        # Konfiguriere Labels für eine binäre Klassifikation\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Erste Faltungsschicht\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Zweite Faltungsschicht\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Dritte Faltungsschicht\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Vierte Faltungsschicht\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Flatten und Dense-Schicht\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Output layer mit einem Künstlichen Neuron, Wertebereich 0-1\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=stepsperepoch,  \n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf die Metriken aus dem history-Objekt\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "for i in range(len(val_accuracy)):\n",
    "    if val_accuracy[i] < 0.01:\n",
    "        if i < (len(val_accuracy)-1) and i > 0:\n",
    "            val_accuracy[i] = (val_accuracy[i-1]+val_accuracy[i+1])/2\n",
    "        elif i > 0:\n",
    "            val_accuracy[i] = val_accuracy[i-1]\n",
    "        else:\n",
    "            val_accuracy[i] = val_accuracy[i+1]\n",
    "\n",
    "    if val_loss[i] < 10**-3:\n",
    "        if i < (len(val_accuracy)-1) and i>0:\n",
    "            val_loss[i] = (val_loss[i-1]+val_loss[i+1])/2\n",
    "        elif i > 0:\n",
    "            val_loss[i] = val_loss[i-1]\n",
    "        else:\n",
    "            val_loss[i] = val_loss[i+1]\n",
    "\n",
    "\n",
    "# Zugriff auf die Anzahl der Epochen\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_accuracy, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Validation Accuracy')\n",
    "plt.title('Training und Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training und Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verzeichnis mit den Testdaten\n",
    "test_dir = './Test/'\n",
    "\n",
    "# ImageDataGenerator für Testdaten\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Generator für Testdaten\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batchsize,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Modell laden\n",
    "#model = tf.keras.models.load_model('dein_model.h5')\n",
    "\n",
    "# Modell auf Testdaten evaluieren\n",
    "eval_result = model.evaluate(test_generator)\n",
    "\n",
    "# Ausgabe von Genauigkeit und Verlust\n",
    "print(\"Test Genauigkeit:\", eval_result[1])\n",
    "print(\"Test Verlust:\", eval_result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
